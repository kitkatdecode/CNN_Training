# -*- coding: utf-8 -*-
"""CNN_Project_cat_dog.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nUUkO-g4nkKzctywT0IwT2Io4jd8nbYk
"""

# zip_path = "/content/drive/My Drive/cats_and_dogs_small.zip"
# !cp "{zip_path}" ./sample_data
# !unzip -q sample_data/cats_and_dogs_small.zip

# !unzip -q sample_data/cats_and_dogs_small.zip

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
# %matplotlib inline
import matplotlib as mpl
import matplotlib.pyplot as plt
import os

import tensorflow as tf
from tensorflow import keras

train_dir = "/content/train"
valid_dir = "/content/validation"
test_dir = "/content/test"

"""**Data preprocessing**

Link : https://keras.io/preprocessing/image/
"""

# data preprocessing
from tensorflow.keras.preprocessing.image import ImageDataGenerator

## generating data batches of (tensor image data)

# making network
from tensorflow.keras import layers
from tensorflow.keras import models

"""General practice : feature size (#filters) increase to double in each next Conv layer

and image size should reduce so add Pooling in between
"""

## compiling model
from tensorflow.keras import optimizers


"""**VGG16**"""

### using VGG16

from tensorflow.keras.applications import VGG16

## borrowing conv_base from VGG

conv_base = VGG16(weights="imagenet",
                include_top=False,
                input_shape=(150,150,3))

model = keras.models.Sequential()

model.add(conv_base)

model.add(layers.Flatten())
model.add(layers.Dense(256, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))

model.summary()

train_datagen = ImageDataGenerator(
    rescale=1.0/255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale=1.0/255)

train_generator = train_datagen.flow_from_directory(
                      train_dir,
                      target_size = (150,150),
                      batch_size= 20,
                      class_mode='binary') # (150, 150) -size of image; y-automatic labels => cats, dogs 

valid_generator = test_datagen.flow_from_directory(
                      valid_dir,
                      target_size = (150,150),
                      batch_size= 20,
                      class_mode='binary')

model.compile(loss="binary_crossentropy", 
              optimizer=optimizers.RMSprop(lr=2e-5),
              metrics=['acc'])

# conv_base.trainable = False # can do this to not train VGG conv

chk_cb = keras.callbacks.ModelCheckpoint("Best_VGG_model.h5", save_best_only=True)

model_history = model.fit(
                    train_generator,
                    steps_per_epoch = 100,
                    epochs=20,
                    validation_data = valid_generator,
                    validation_steps= 50,
                    callbacks=[chk_cb])

pd.DataFrame(model_history.history).plot(figsize=(8, 5))
plt.grid(True)
plt.gca().set_ylim(0, 1)
plt.show()

# storing history in csv
hist_df = pd.DataFrame(model_history.history)

hist_csv = "model_history.csv"

with open(hist_csv, mode='w') as f:
  hist_df.to_csv(f)

# evaluating on test data
test_generator = test_datagen.flow_from_directory(
        test_dir,
        target_size=(150, 150),
        batch_size=20,
        class_mode='binary')

model.evaluate(test_generator, steps=50)