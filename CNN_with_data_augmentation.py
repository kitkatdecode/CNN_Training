# -*- coding: utf-8 -*-
"""CNN_Project_cat_dog.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nUUkO-g4nkKzctywT0IwT2Io4jd8nbYk
"""

# zip_path = "/content/drive/My Drive/cats_and_dogs_small.zip"
# !cp "{zip_path}" ./sample_data
# !unzip -q sample_data/cats_and_dogs_small.zip

# !unzip -q sample_data/cats_and_dogs_small.zip

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
# %matplotlib inline
import matplotlib as mpl
import matplotlib.pyplot as plt
import os

import tensorflow as tf
from tensorflow import keras

# paths to directories need to set before using this code
train_dir = "/content/train"
valid_dir = "/content/validation"
test_dir = "/content/test"

"""**Data preprocessing**

Link : https://keras.io/preprocessing/image/
"""

# data preprocessing
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1.0/255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale=1.0/255)

train_generator = train_datagen.flow_from_directory(
                      train_dir,
                      target_size = (150,150),
                      batch_size= 20,
                      class_mode='binary') # (150, 150) -size of image; y-automatic labels => cats, dogs 

valid_generator = test_datagen.flow_from_directory(
                      valid_dir,
                      target_size = (150,150),
                      batch_size= 20,
                      class_mode='binary')

model = models.Sequential()

model.add(layers.Conv2D(filters=32,kernel_size=(3,3), strides=1,padding='valid',activation='relu',input_shape=(150,150,3)))
model.add(layers.MaxPooling2D((2,2))) # half the image size ; here 75x75x3

model.add(layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2))) # 37x37x3

model.add(layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2))) # 18x18x3

model.add(layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2))) # 9x9x3

model.add(layers.Flatten()) #flatten to linear layer
model.add(layers.Dropout(0.5)) # deactivate 50% neurons (randomly) - effective for overfitting
model.add(layers.Dense(512, activation='relu'))

model.add(layers.Dense(1, activation='sigmoid')) ## 1 neuron only because only two classes ; with sigmoid

model.compile(loss="binary_crossentropy", 
              optimizer=optimizers.RMSprop(lr=1e-4),
              metrics=['acc'])

chk_cb = keras.callbacks.ModelCheckpoint("Best_model.h5", save_best_only=True)

model_history = model.fit(
                    train_generator,
                    steps_per_epoch = 100,
                    epochs=20,
                    validation_data = valid_generator,
                    validation_steps= 50,
                    callbacks=[chk_cb])

pd.DataFrame(model_history.history).plot(figsize=(8, 5))
plt.grid(True)
plt.gca().set_ylim(0, 1)
plt.show()